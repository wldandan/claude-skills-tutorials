# 特性 08: 智能根因分析 (RCA)

## 功能概述

提供智能化的根因分析（Root Cause Analysis）能力，基于异常检测、关联分析、因果推断等技术，自动识别问题的根本原因，而不仅仅是表面症状。通过构建因果关系图、分析异常传播路径、生成根因假设，帮助运维人员快速找到问题的根本原因并制定解决方案。

## 用户场景

**场景 1: 服务不可用，需要快速找到根因**
- 关键服务宕机，影响业务
- 需要快速识别是配置错误、资源耗尽还是代码缺陷
- 使用 `aiops rca --service nginx --downtime 2024-01-15T14:15:00` 自动分析

**场景 2: 性能下降，需要找出根本原因**
- 应用性能下降 50%，原因不明
- 需要区分是容量问题、代码回归还是依赖服务问题
- 使用 `aiops rca --symptom "性能下降" --baseline "1天前"` 对比分析

**场景 3: 重复性问题，需要根治**
- 某类问题反复出现，只能临时缓解
- 需要找到根本原因并彻底解决
- 使用 `aiops rca --recurring --pattern analyze` 识别重复模式

## 技术方案概要

### 因果发现
- **结构因果模型 (SCM)**: 基于因果图理论构建因果关系
- **PC 算法**: Peter-Clark 算法发现因果结构
- **LiNGAM**: 线性非高斯无环模型识别因果方向
- **Granger 因果检验**: 时序数据的因果检验
- **干预分析**: 基于干预效果的因果推断

### 根因假设生成
- **异常传播分析**: 追踪异常从源头到症状的传播路径
- **时间序列因果**: 分析指标间的时序因果关系
- **知识图谱**: 基于运维知识库的规则推理
- **历史案例匹配**: 匹配相似历史问题的根因
- **专家系统**: 基于规则的专家系统推理

### 根因验证
- **反事实推理**: "如果 X 不发生，Y 还会发生吗？"
- **干预模拟**: 模拟干预措施的效果
- **A/B 测试**: 对比实验验证根因假设
- **用户反馈**: 收集用户对根因分析的反馈

## 核心功能点

### 1. 自动根因分析
```bash
# 自动分析根因
aiops rca --event 2024-01-15T14:15:00 --auto
```
- 自动采集异常时间窗口的数据
- 构建因果关系图
- 生成根因假设
- 计算根因置信度
- 提供验证步骤

### 2. 对比根因分析
```bash
# 对比正常和异常时段
aiops rca --compare --normal "2024-01-15 10:00-11:00" --anomaly "2024-01-15 14:00-15:00"
```
- 对比正常时段和异常时段的差异
- 识别显著变化的指标
- 分析变化的原因
- 推断根因

### 3. 因果关系图
```bash
# 生成因果关系图
aiops rca --causal-graph --event 2024-01-15T14:15:00
```
- 构建指标间的因果关系图
- 显示因果路径
- 标注异常传播路径
- 可视化输出（DOT、PNG）

### 4. 根因假设管理
```bash
# 管理根因假设
aiops rca --hypotheses --list
aiops rca --hypothesis <id> --verify
```
- 列出所有根因假设
- 查看假设详情和证据
- 验证假设（标记为确认/排除）
- 学习验证结果（反馈到模型）

### 5. 历史案例匹配
```bash
# 匹配历史案例
aiops rca --match-history --event 2024-01-15T14:15:00
```
- 查找相似的历史事件
- 显示历史事件的根因
- 显示历史解决方案
- 推荐适用性

### 6. 5 Why 分析
```bash
# 5 Why 分析
aiops rca --five-why --symptom "服务不可用"
```
- 连续追问 5 次 "为什么"
- 构建问题链
- 找到根本原因
- 生成 Why-Why 图

### 7. 鱼骨图分析
```bash
# 鱼骨图 (石川图) 分析
aiops rca --fishbone --symptom "性能下降"
```
- 按维度分类（人、机、料、法、环）
- 列出每个维度的可能原因
- 逐个排查
- 生成鱼骨图

### 8. 根因报告生成
```bash
# 生成根因分析报告
aiops rca --report --event 2024-01-15T14:15:00 --output rca_report.md
```
- 生成完整的根因分析报告
- 包含问题描述、分析过程、根因、解决方案
- 支持多种格式（Markdown、PDF、HTML）
- 可用于事后复盘

## 验收标准 (Acceptance Criteria)

### AC 1: 因果关系发现准确性
- **Given**: 已知因果关系（如 CPU 高 → 负载高）
- **When**: 执行 `aiops rca --causal-graph`
- **Then**:
  - 正确识别因果关系（准确率 >= 80%，基于标注数据）
  - 因果方向正确（A → B，不是 B → A）
  - 因果强度评估合理

### AC 2: 根因假设质量
- **Given**: 已知故障场景
- **When**: 执行 `aiops rca --auto --event <timestamp>`
- **Then**:
  - 生成的 Top 3 假设包含真实根因（准确率 >= 70%）
  - 根因置信度计算合理
  - 提供的证据充分

### AC 3: 5 Why 分析深度
- **Given**: 已知问题症状
- **When**: 执行 `aiops rca --five-why --symptom <symptom>`
- **Then**:
  - 能够连续追问至少 5 层 Why
  - 每层的答案合理且可验证
  - 最终找到根本原因

### AC 4: 历史案例匹配准确性
- **Given**: 历史案例库中有相似案例
- **When**: 执行 `aiops rca --match-history`
- **Then**:
  - 找到相关历史案例（Top 5 中至少 3 个相关）
  - 相似度计算合理
  - 推荐的解决方案可操作

### AC 5: 性能与资源占用
- **Given**: 系统运行正常
- **When**: 执行 `aiops rca --auto --event <timestamp>`
- **Then**:
  - 分析时间 < 60 秒（1 小时数据窗口）
  - 内存占用 < 2GB
  - CPU 占用 < 50%（短时间）

### AC 6: 根因验证准确性
- **Given**: 用户验证根因假设
- **When**: 执行 `aiops rca --hypothesis <id> --verify --confirmed`
- **Then**:
  - 验证结果正确记录
  - 模型从验证结果中学习
  - 后续类似问题的分析准确率提升

### AC 7: 鱼骨图完整性
- **Given**: 复杂问题（多个维度）
- **When**: 执行 `aiops rca --fishbone --symptom <symptom>`
- **Then**:
  - 覆盖所有主要维度（人、机、料、法、环）
  - 每个维度列出至少 3 个可能原因
  - 鱼骨图可视化清晰

### AC 8: 报告生成质量
- **Given**: 完成根因分析
- **When**: 执行 `aiops rca --report --event <timestamp>`
- **Then**:
  - 报告包含所有必要章节（概述、症状、分析、根因、方案）
  - 报告逻辑清晰、结论明确
  - 支持导出为 Markdown/PDF

## 依赖项

### 系统依赖
- **操作系统**: Linux (内核 >= 3.10)
- **Python**: Python 3.8+

### Python 库依赖
```
pandas>=2.0.0          # 数据处理
numpy>=1.24.0          # 数值计算
scipy>=1.10.0          # 统计分析
scikit-learn>=1.3.0    # 机器学习
networkx>=3.1          # 图分析（因果关系图）
click>=8.1.0           # CLI 框架
rich>=13.0.0           # 终端美化
```

### 可选依赖
```
dowhy>=0.11.0          # 因果推断库
econml>=0.14.0         # 经济学因果推断
matplotlib>=3.7.0      # 图可视化
pydot>=1.4.0           # DOT 图生成
```

## 优先级

**P0 (必须实现)**
- AC 5: 性能与资源占用
- 核心功能点 1, 6

**P1 (首版本必备)**
- AC 2: 根因假设质量
- AC 3: 5 Why 分析
- AC 8: 报告生成
- 核心功能点 2, 5, 8

**P2 (后续版本优化)**
- AC 1: 因果关系发现
- AC 4: 历史案例匹配
- AC 6: 根因验证
- AC 7: 鱼骨图
- 核心功能点 3, 4, 7

## 输出示例

### 自动根因分析输出
```bash
$ aiops rca --auto --event 2024-01-15T14:15:00

┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ 智能根因分析报告                                     2024-01-15 14:30:25 ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ 异常事件: 2024-01-15 14:15:23                                  │
│ 症状: Java 应用服务不可用（OOM kill 后重启）                     │
│ 影响持续时间: 5 分 22 秒                                        │
├──────────────────────────────────────────────────────────────────┤
│ 🔍 分析过程:                                                      │
│   1. 数据采集: 已完成 (时间窗口: 14:05-14:25, 共 20 分钟)        │
│   2. 异常检测: 检测到 2 个异常时段                              │
│   3. 关联分析: 识别出 15 个相关指标                             │
│   4. 因果推断: 构建因果关系图（23 个节点，31 条边）              │
│   5. 根因假设: 生成 5 个根因假设                                │
├──────────────────────────────────────────────────────────────────┤
│ 📊 症状分析:                                                      │
│   直接症状:                                                      │
│     • Java 进程被 OOM killer 终止 (PID 15234)                   │
│     • 应用服务不可用 (HTTP 502/503)                             │
│     • 系统负载高 (Load average: 15.2)                           │
│                                                                  │
│   间接症状:                                                      │
│     • 系统内存使用率 98% (基线 52%)                             │
│     • Swap 使用率 63% (基线 5%)                                 │
│     • CPU 等待 IO 增加                                          │
├──────────────────────────────────────────────────────────────────┤
│ 🎯 根因假设 (按置信度排序):                                       │
│                                                                  │
│ 假设 #1: Java 进程内存泄漏 (置信度: 92%) ⭐                        │
│   ┌────────────────────────────────────────────────────────┐   │
│   │ 因果链:                                               │   │
│   │   1. Java 进程存在内存泄漏 (堆内存持续增长)              │   │
│   │   2. 堆内存接近上限 (-Xmx4G)                            │   │
│   │   3. GC 频率增加，GC pause 时间增长                      │   │
│   │   4. CPU 用于 GC，应用响应变慢                           │   │
│   │   5. 内存不足，触发 OOM killer                          │   │
│   │   6. Java 进程被 kill，应用不可用                       │   │
│   │                                                      │   │
│   │ 证据:                                                 │   │
│   │   • 堆内存趋势: 1.2GB → 4.0GB (+233%)                  │   │
│   │   • GC 统计: Minor GC 15 次/小时 → 45 次/小时           │   │
│   │   • GC pause: 平均 200ms → 800ms                       │   │
│   │   • 日志: "java.lang.OutOfMemoryError: Java heap space" │   │
│   │                                                      │   │
│   │ 验证步骤:                                             │   │
│   │   1. 分析堆转储: jmap -dump:live,format=b,file=heap.hprof 15234
│   │   2. 检查 GC 日志: grep "GC" /var/log/app.log          │   │
│   │   3. 分析堆对象: MAT - OQL 查询大对象                   │   │
│   │                                                      │   │
│   │ 解决方案:                                             │   │
│   │   短期: 重启进程，增加堆内存 (-Xmx8G)                   │   │
│   │   长期: 修复内存泄漏，优化内存使用                      │   │
│   └────────────────────────────────────────────────────────┘   │
│                                                                  │
│ 假设 #2: Java 堆内存配置不足 (置信度: 65%)                       │
│   ┌────────────────────────────────────────────────────────┐   │
│   │ 因果链:                                               │   │
│   │   1. 业务流量增加，内存需求增长                          │   │
│   │   2. 堆内存配置 (4GB) 不足以支撑负载                     │   │
│   │   3. 峰值内存达到上限                                   │   │
│   │   4. 触发 OOM                                          │   │
│   │                                                      │   │
│   │ 证据:                                                 │   │
│   │   • 异常时段流量 +50%                                   │   │
│   │   • 峰值内存 3.9GB，接近上限 4GB                        │   │
│   │   • 历史峰值从未超过 3.5GB                              │   │
│   │                                                      │   │
│   │ 验证步骤:                                             │   │
│   │   1. 检查堆内存配置: jinfo -flag MaxHeapSize 15234     │   │
│   │   2. 分析流量趋势: aiops analyze traffic --app         │   │
│   │   3. 容量规划: 计算所需内存                             │   │
│   │                                                      │   │
│   │ 解决方案:                                             │   │
│   │   短期: 增加堆内存 (-Xmx8G)                            │   │
│   │   长期: 容量规划，动态扩容                             │   │
│   └────────────────────────────────────────────────────────┘   │
│                                                                  │
│ 假设 #3: 突发流量导致内存峰值 (置信度: 30%)                       │
│   证据不足，需验证                                              │
│                                                                  │
│ 假设 #4: 依赖服务内存泄漏 (置信度: 20%)                          │
│   证据不足，需验证                                              │
│                                                                  │
│ 假设 #5: JVM Bug 或异常行为 (置信度: 5%)                         │
│   可能性极低，需验证                                            │
│                                                                  │
├──────────────────────────────────────────────────────────────────┤
│ 📈 因果关系图:                                                    │
│                                                                  │
│         内存泄漏 (Java 代码)                                      │
│              ↓                                                   │
│         堆内存增长                                                │
│              ↓                                                   │
│         GC 频率增加                                               │
│              ↓                                                   │
│         CPU 使用率上升                                            │
│              ↓                                                   │
│         应用响应变慢                                              │
│              ↓                                                   │
│         内存不足                                                  │
│              ↓                                                   │
│         OOM killer 触发                                          │
│              ↓                                                   │
│         进程终止 → 服务不可用                                     │
│                                                                  │
├──────────────────────────────────────────────────────────────────┤
│ 🎯 最终结论:                                                      │
│   根本原因: Java 应用程序存在内存泄漏                              │
│   置信度: 92%                                                    │
│   问题类型: 应用缺陷（代码问题）                                  │
│   责任方: 应用开发团队                                           │
│   优先级: P0 (紧急)                                             │
│                                                                  │
├──────────────────────────────────────────────────────────────────┤
│ 💡 推荐行动:                                                      │
│   立即 (0-1 小时):                                               │
│     1. 重启 Java 服务: systemctl restart java-service            │
│     2. 临时增加堆内存: -Xmx8G                                    │
│     3. 监控内存使用: aiops monitor memory --pid <new_pid>         │
│                                                                  │
│   短期 (1-3 天):                                                │
│     1. 生成堆转储分析: jmap -dump <pid>                          │
│     2. 分析内存泄漏: MAT、jhat                                   │
│     3. 添加详细 GC 日志: -Xlog:gc*                              │
│     4. 配置 OOM 告警: aiops alert create --condition oom         │
│                                                                  │
│   长期 (1-2 周):                                                │
│     1. 修复内存泄漏代码                                          │
│     2. 进行代码审查和测试                                        │
│     3. 实施容量规划和自动扩容                                    │
│     4. 定期进行内存泄漏检测                                      │
│                                                                  │
└──────────────────────────────────────────────────────────────────┘

📎 生成详细报告: aiops rca --report --event 2024-01-15T14:15:00 --output rca_report.md
```

### 5 Why 分析输出
```bash
$ aiops rca --five-why --symptom "服务响应慢"

┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ 5 Why 根因分析                                      2024-01-15 14:30:25 ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ 症状: 服务响应慢 (平均响应时间 5s，基线 200ms)                   │
├──────────────────────────────────────────────────────────────────┤
│ 🔍 5 Why 分析过程:                                               │
│                                                                  │
│   Why #1: 为什么服务响应慢？                                      │
│   → 答: 因为 API 请求处理时间从 200ms 增加到 5s                  │
│   证据: 应用性能监控 (APM) 数据                                   │
│                                                                  │
│   Why #2: 为什么 API 请求处理时间增加？                           │
│   → 答: 因为数据库查询耗时从 50ms 增加到 4.5s                    │
│   证据: 慢查询日志、数据库性能监控                               │
│                                                                  │
│   Why #3: 为什么数据库查询耗时增加？                              │
│   → 答: 因为数据库缺少索引，查询执行全表扫描                      │
│   证据: EXPLAIN 分析显示 type=ALL                               │
│                                                                  │
│   Why #4: 为什么数据库缺少索引？                                  │
│   → 答: 因为上次 schema 变更时索引被误删                          │
│   证据: Git 历史、变更日志                                       │
│                                                                  │
│   Why #5: 为什么上次变更时索引被误删？                            │
│   → 答: 因为变更流程缺少索引验证步骤，Review 不充分                │
│   证据: 变更工单、Code Review 记录                               │
│                                                                  │
├──────────────────────────────────────────────────────────────────┤
│ 🎯 根本原因:                                                      │
│   流程问题: 变更管理流程不完善，缺少必要的验证步骤                 │
│   而非技术问题: 缺少索引只是表面现象                             │
│                                                                  │
├──────────────────────────────────────────────────────────────────┤
│ 💡 永久解决方案:                                                  │
│   流程改进:                                                      │
│     1. 在 schema 变更流程中添加索引验证步骤                      │
│     2. 实施变更前后的性能对比测试                                │
│     3. 加强 Code Review，强制索引检查                           │
│     4. 自动化回归测试（包含慢查询检测）                           │
│                                                                  │
│   技术修复:                                                      │
│     1. 立即添加缺失的索引:                                       │
│        ALTER TABLE orders ADD INDEX idx_customer_id (customer_id);
│     2. 验证索引效果: EXPLAIN SELECT ...                          │
│     3. 监控慢查询: aiops analyze database --slow-queries         │
│                                                                  │
└──────────────────────────────────────────────────────────────────┘
```

## 后续演进方向

1. **因果机器学习**: 深度学习和因果推断结合
2. **强化学习**: 基于反馈的根因分析优化
3. **知识图谱**: 构建运维知识图谱，支持推理
4. **自动化修复**: 从根因到自动修复的闭环
